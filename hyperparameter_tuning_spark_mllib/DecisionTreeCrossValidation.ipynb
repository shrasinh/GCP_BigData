{"cells":[{"cell_type":"markdown","id":"55114c59","metadata":{},"source":["# Decision Tree Classification for MNIST with Cross-Validation\n","\n","In this notebook, a demonstration is provided of how PySpark's Decision Tree classifier can be utilized with automated hyperparameter tuning via cross-validation to classify handwritten digits from the MNIST dataset."]},{"cell_type":"markdown","id":"2b4fe073","metadata":{},"source":["## Setup and Data Loading\n","\n","The MNIST dataset in LibSVM format is first downloaded and loaded into the Spark environment:\n","\n","1. The training and test datasets are downloaded\n","2. The files are decompressed\n","3. They are loaded into HDFS for Spark processing\n","4. The data is read using Spark's libsvm reader"]},{"cell_type":"code","execution_count":1,"id":"e9591217","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-03-23 00:54:35--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.bz2\n","Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n","Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 15179306 (14M) [application/x-bzip2]\n","Saving to: ‘mnist.bz2’\n","\n","mnist.bz2           100%[===================>]  14.48M  7.30MB/s    in 2.0s    \n","\n","2025-03-23 00:54:38 (7.30 MB/s) - ‘mnist.bz2’ saved [15179306/15179306]\n","\n","--2025-03-23 00:54:38--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.t.bz2\n","Reusing existing connection to www.csie.ntu.edu.tw:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2508388 (2.4M) [application/x-bzip2]\n","Saving to: ‘mnist.t.bz2’\n","\n","mnist.t.bz2         100%[===================>]   2.39M  --.-KB/s    in 0.02s   \n","\n","2025-03-23 00:54:38 (101 MB/s) - ‘mnist.t.bz2’ saved [2508388/2508388]\n","\n","FINISHED --2025-03-23 00:54:38--\n","Total wall clock time: 3.3s\n","Downloaded: 2 files, 17M in 2.0s (8.41 MB/s)\n"]}],"source":["!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.bz2 https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/mnist.t.bz2\n","!bzip2 -d mnist.bz2 mnist.t.bz2"]},{"cell_type":"code","execution_count":2,"id":"0303091e","metadata":{},"outputs":[],"source":["!hdfs dfs -put -f mnist \n","!hdfs dfs -put -f mnist.t"]},{"cell_type":"code","execution_count":3,"id":"d1ed317f","metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.ml import Pipeline\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"]},{"cell_type":"code","execution_count":4,"id":"f7209ed4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/03/23 00:56:04 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","25/03/23 00:56:23 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","[Stage 6:=============================>                             (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["There are 60000 training images and 10000 test images.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Load MNIST training and test datasets\n","# These datasets are stored in the LibSVM format\n","training = spark.read.format(\"libsvm\").load(\"mnist\")\n","test = spark.read.format(\"libsvm\").load(\"mnist.t\")\n","\n","# Cache data for multiple uses\n","training.cache()\n","test.cache()\n","\n","print(f\"There are {training.count()} training images and {test.count()} test images.\")"]},{"cell_type":"code","execution_count":5,"id":"b9b95674","metadata":{},"outputs":[{"data":{"text/plain":["DataFrame[label: double, features: vector]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["+-----+--------------------+\n","|label|            features|\n","+-----+--------------------+\n","|  5.0|(780,[152,153,154...|\n","|  0.0|(780,[127,128,129...|\n","|  4.0|(780,[160,161,162...|\n","|  1.0|(780,[158,159,160...|\n","|  9.0|(780,[208,209,210...|\n","|  2.0|(780,[155,156,157...|\n","|  1.0|(780,[124,125,126...|\n","|  3.0|(780,[151,152,153...|\n","|  1.0|(780,[152,153,154...|\n","|  4.0|(780,[134,135,161...|\n","+-----+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Display the data\n","display(training)\n","training.show(n=10)"]},{"cell_type":"markdown","id":"1b8062ed","metadata":{},"source":["## Pipeline Construction\n","\n","A machine learning pipeline is built consisting of:\n","- A `StringIndexer` to convert the label column to a format suitable for classification\n","- A `DecisionTreeClassifier` as the model"]},{"cell_type":"code","execution_count":6,"id":"cddd37bc","metadata":{},"outputs":[],"source":["# Set up the pipeline components\n","# StringIndexer: Read input column \"label\" (digits) and annotate them as categorical values\n","indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n","\n","# DecisionTreeClassifier: Learn to predict column \"indexedLabel\" using the \"features\" column\n","dtc = DecisionTreeClassifier(labelCol=\"indexedLabel\")\n","\n","# Chain indexer + dtc together into a single ML Pipeline\n","pipeline = Pipeline(stages=[indexer, dtc])"]},{"cell_type":"markdown","id":"a427c816","metadata":{},"source":["## Hyperparameter Tuning\n","\n","To find the optimal model hyperparameters, cross-validation is implemented:\n","- A parameter grid is created for different tree depths (0-7) and bin sizes (2, 4, 8, 16, 32)\n","- 3-fold cross-validation is employed to evaluate each parameter combination\n","- The model with the highest weighted precision is selected"]},{"cell_type":"code","execution_count":7,"id":"9e6d4f87","metadata":{},"outputs":[],"source":["# Define an evaluation metric\n","evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"indexedLabel\",\n","    predictionCol=\"prediction\",\n","    metricName=\"weightedPrecision\"\n",")"]},{"cell_type":"code","execution_count":8,"id":"8286abf1","metadata":{},"outputs":[],"source":["# Build parameter grid for CrossValidator\n","paramGrid = ParamGridBuilder() \\\n","    .addGrid(dtc.maxDepth, range(0,8)) \\\n","    .addGrid(dtc.maxBins, [2, 4, 8, 16, 32]) \\\n","    .build()"]},{"cell_type":"code","execution_count":9,"id":"7cf29d82","metadata":{},"outputs":[],"source":["# Create the CrossValidator\n","cv = CrossValidator(\n","    estimator=pipeline,\n","    estimatorParamMaps=paramGrid,\n","    evaluator=evaluator,\n","    numFolds=3\n",")"]},{"cell_type":"code","execution_count":10,"id":"8ff24775","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training models with cross-validation...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Run cross-validation and select the best model\n","print(\"Training models with cross-validation...\")\n","cvModel = cv.fit(training)"]},{"cell_type":"markdown","id":"7e2e2f7f","metadata":{},"source":["## Model Evaluation\n","\n","After training:\n","1. The best model and its parameters are extracted\n","2. Performance is evaluated on both training and test datasets\n","3. The best model configuration and its weighted precision metrics are reported"]},{"cell_type":"code","execution_count":11,"id":"b4244180","metadata":{},"outputs":[{"data":{"text/plain":["DecisionTreeClassificationModel: uid=DecisionTreeClassifier_4d05f4924530, depth=7, numNodes=245, numClasses=10, numFeatures=780"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Best model parameters:\n","maxDepth: 7\n","maxBins: 8\n"]}],"source":["# Get the best model\n","bestModel = cvModel.bestModel\n","bestPipelineModel = bestModel\n","\n","# Extract the decision tree model (the last stage of the pipeline)\n","bestTreeModel = bestPipelineModel.stages[-1]\n","\n","display(bestTreeModel)\n","\n","# Print the best model parameters\n","print(\"Best model parameters:\")\n","print(f\"maxDepth: {bestTreeModel.getMaxDepth()}\")\n","print(f\"maxBins: {bestTreeModel.getMaxBins()}\")"]},{"cell_type":"code","execution_count":12,"id":"39fa1a3d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training weighted precision: 0.7915121381227309\n"]}],"source":["# Make predictions on training data using the best model\n","predictions_train = bestPipelineModel.transform(training)\n","\n","# Evaluate the model on the training dataset\n","weighted_precision_train = evaluator.evaluate(predictions_train)\n","print(f\"Training weighted precision: {weighted_precision_train}\")"]},{"cell_type":"code","execution_count":13,"id":"27bf89ce","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test weighted precision: 0.7946790596293032\n"]}],"source":["# Make predictions on test data using the best model\n","predictions = bestPipelineModel.transform(test)\n","\n","# Evaluate the model on the test dataset\n","weighted_precision_test = evaluator.evaluate(predictions)\n","print(f\"Test weighted precision: {weighted_precision_test}\")"]},{"cell_type":"code","execution_count":null,"id":"f4a7515a","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}